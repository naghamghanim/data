{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38485,"status":"ok","timestamp":1687440213822,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"27ecrRm8Giod","outputId":"9cbd3ad8-7c55-4c75-8b72-a655d0f791ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14340,"status":"ok","timestamp":1687440175342,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"Xgh12HXJUbwi","outputId":"f4466142-a151-4e12-893c-fbd4335c1149"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8515,"status":"ok","timestamp":1687440233539,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"RxmY4izoUzDs","outputId":"9141c46a-ef0a-4fb0-e9ff-9a26875c9c37"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyiuDzOeVMU2"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1687440241248,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"pegbKRPjUgmm","outputId":"c0089204-6749-4246-ae68-bab40b605149"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.1+cu118\n"]}],"source":["print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShyVkQ7oV7Ll"},"outputs":[],"source":["# model_path = '/content/drive/MyDrive/masters/araber_putourch/bert-base-arabertv01'\n","# model_path = '/content/drive/MyDrive/masters/araber_putourch/bert-base-arabert'\n","# model_path = '/content/drive/MyDrive/bert-base-arabert'\n","#model_path = 'UBC-NLP/ARBERT'\n","model_path = 'aubmindlab/bert-base-arabertv02'\n","# # no seg\n","# model_path = 'aubmindlab/bert-large-arabertv02'\n","# # seg\n","# model_path ='aubmindlab/bert-base-arabertv2'\n","# # seg\n","# model_path = 'aubmindlab/bert-large-arabertv2'\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["42267800a25540c980dbc9eeacafaeca","6be1c959aa294505a8a34f67a333ad3d","e6972d3b6d56436f815337fdcd999cf8","6d01ac8faecd40b2966b0291fb4edf65","9ae6c63df7124e9c91a4f5e7a21007fe","50d85f84abee4d5cadaf0a4c12703ae2","02d2b6e37158448e89099e42b690a38e","f323160c757249479434e2724e501ab8","38947973d4bb4a73bd5a8bfbacb85885","ad58c1c205dd4dc0969a66822860c25f","30de6934fb0349c2b74c121897e79aca","d58382cfbc6249018351a2e353d43368","7e21a719db0440f38474d1e10900c9b9","98390f53fc02423da5ba77885b09a247","150f139641bf47bda20e3c59cab5f072","485d34a73e944e65acbb2e22ce12c286","e1b0598b83a84801964126ef41c99f71","4ac73de6825b49baa03329429f9c1486","02f6fbe8fec2442a8c53594cd47e86be","c2af1ab7b81f4b7e829a1efd515abf6e","5c98ff8aefb649cda399f4de5a01dccf","caabed851a2440caae4f241c58e2a6f7","07aaeed6f610403f85be74888826acbe","5a3a32b795984105848d7964ef8f9975","c8a96f2a17594bd9bbeb9e04f6273d69","4cb688907f7442a7b5511e5d1a4f02eb","8a3dccf5cd5147339febb57fda7ec673","5883123b5a8b42589af29d1a190adac4","dd966526b04b463aa516c85291560e6f","45425c9b772f441697ccac4edf8ec7e7","eed9280b54254569b3c21fe2277a9cc1","adeb407035dc43488b59f94331be48be","febe57df0d0b4023b5b257483ee2c3a0","639217c3add64bfdbf66ba3bacacae0e","6cdff14b059f43b99a9ddd32a3fb3070","dd8b3f39bfbe44a69b818a667cac3215","84d82a2d64c14382b03d31ec6f017e03","abdb738b1bec4df78d99147765a728bc","eea13ec7baa742568baf0b1114b5fa62","9cbef5f6b7dc4335a078ebd8e89e00dc","5791c87669594f61bdf628b89f57e20c","2453bd7e013344509b4474375780f79d","b6f627dc990549f296a74bbfc5271b13","c56d57f1428a4f19bd37a4f69983a270"]},"executionInfo":{"elapsed":2434,"status":"ok","timestamp":1687440243669,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"9lE4RVzLUxT7","outputId":"7cfd1516-49f5-4b24-bd72-0e85b97d4719"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading BERT tokenizer...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42267800a25540c980dbc9eeacafaeca","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d58382cfbc6249018351a2e353d43368","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07aaeed6f610403f85be74888826acbe","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/381 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"639217c3add64bfdbf66ba3bacacae0e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BertTokenizer\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dN-o_A8HTPvg"},"outputs":[],"source":["benchmark_path = \"/content/drive/MyDrive/Colab_Notebooks/Arabic-word-sense-disambiguation-bench-mark-main/new_df_pairs.parquet\"\n","df = pd.read_parquet(benchmark_path)\n","# df = pd.read_parquet(\"/content/drive/MyDrive/masters/new_df_pairs_with_all_postive_ex\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1687440249880,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"5MUeYwCecUC5","outputId":"85a3c410-a3dc-4796-e872-4738656fdd6d"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-4fc56d46-4208-4fe5-820f-f8bd8d468602\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>word</th>\n","      <th>def</th>\n","      <th>ex</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9761</td>\n","      <td>آثر</td>\n","      <td>: آثر الشيء فضله واختاره   { } .</td>\n","      <td>بل تؤثرون الحياة الدنيا</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9761</td>\n","      <td>آثر</td>\n","      <td>: آثره على نفسه: قدمه واختصه بالخير :- { } .</td>\n","      <td>بل تؤثرون الحياة الدنيا</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9762</td>\n","      <td>آثر</td>\n","      <td>: آثر الشيء فضله واختاره   { } .</td>\n","      <td>ويؤثرون على أنفسهم ولو كان بهم خصاصة</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9762</td>\n","      <td>آثر</td>\n","      <td>: آثره على نفسه: قدمه واختصه بالخير :- { } .</td>\n","      <td>ويؤثرون على أنفسهم ولو كان بهم خصاصة</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8364</td>\n","      <td>آخذ</td>\n","      <td>: آخذ الرجل عاتبه، لامه وعابه   { }</td>\n","      <td>قال لا تؤاخذني بما نسيت ولا ترهقني من أمري عسرا</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31093</th>\n","      <td>54579</td>\n","      <td>يومية</td>\n","      <td>: مصدر صناعي من يوم: أجر العامل اليومي</td>\n","      <td>:-عاملة يومية، -</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>31094</th>\n","      <td>54580</td>\n","      <td>يومية</td>\n","      <td>: اسم مؤنث منسوب إلى يوم:   جريدة يومية: تصدر ...</td>\n","      <td>:-يعمل باليومية.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>31095</th>\n","      <td>54580</td>\n","      <td>يومية</td>\n","      <td>: مصدر صناعي من يوم: أجر العامل اليومي</td>\n","      <td>:-يعمل باليومية.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>31096</th>\n","      <td>54581</td>\n","      <td>يومية</td>\n","      <td>: اسم مؤنث منسوب إلى يوم:   جريدة يومية: تصدر ...</td>\n","      <td>:-دون يومياته، -</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>31097</th>\n","      <td>54581</td>\n","      <td>يومية</td>\n","      <td>: السجل الذي يدون فيه الشخص انطباعاته يوميا، ا...</td>\n","      <td>:-دون يومياته، -</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31098 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fc56d46-4208-4fe5-820f-f8bd8d468602')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fc56d46-4208-4fe5-820f-f8bd8d468602 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fc56d46-4208-4fe5-820f-f8bd8d468602');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          ID   word                                                def  \\\n","0       9761    آثر                   : آثر الشيء فضله واختاره   { } .   \n","1       9761    آثر       : آثره على نفسه: قدمه واختصه بالخير :- { } .   \n","2       9762    آثر                   : آثر الشيء فضله واختاره   { } .   \n","3       9762    آثر       : آثره على نفسه: قدمه واختصه بالخير :- { } .   \n","4       8364    آخذ                : آخذ الرجل عاتبه، لامه وعابه   { }   \n","...      ...    ...                                                ...   \n","31093  54579  يومية             : مصدر صناعي من يوم: أجر العامل اليومي   \n","31094  54580  يومية  : اسم مؤنث منسوب إلى يوم:   جريدة يومية: تصدر ...   \n","31095  54580  يومية             : مصدر صناعي من يوم: أجر العامل اليومي   \n","31096  54581  يومية  : اسم مؤنث منسوب إلى يوم:   جريدة يومية: تصدر ...   \n","31097  54581  يومية  : السجل الذي يدون فيه الشخص انطباعاته يوميا، ا...   \n","\n","                                                    ex  label  \n","0                              بل تؤثرون الحياة الدنيا      1  \n","1                              بل تؤثرون الحياة الدنيا      0  \n","2                 ويؤثرون على أنفسهم ولو كان بهم خصاصة      0  \n","3                 ويؤثرون على أنفسهم ولو كان بهم خصاصة      1  \n","4      قال لا تؤاخذني بما نسيت ولا ترهقني من أمري عسرا      1  \n","...                                                ...    ...  \n","31093                                 :-عاملة يومية، -      0  \n","31094                                 :-يعمل باليومية.      0  \n","31095                                 :-يعمل باليومية.      1  \n","31096                                 :-دون يومياته، -      0  \n","31097                                 :-دون يومياته، -      1  \n","\n","[31098 rows x 5 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdSsPPJuWfSE"},"outputs":[],"source":["new_df_pairs = df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QsqaoKPYWBqF"},"outputs":[],"source":["new_df_pairs['input_sentence'] =new_df_pairs.apply(lambda row : '[CLS] '+row['ex']+' [SEP] '+row['def'],axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRmrzSMbTZ4N"},"outputs":[],"source":["new_df_pairs.sample(frac=1)\n","msk = np.random.rand(len(new_df_pairs)) < 0.8\n","new_train = new_df_pairs[msk]\n","test = new_df_pairs[~msk]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40233,"status":"ok","timestamp":1687440305911,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"9wze6reFVH2g","outputId":"52c1c094-480a-4953-ed77-27978c960d02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original:  [CLS] بل تؤثرون الحياة الدنيا [SEP] : آثر الشيء فضله واختاره   { } .\n","Token IDs: [2, 549, 1275, 527, 319, 1725, 6449, 3, 31, 4164, 8110, 6819, 195, 29413, 195, 96, 98, 20]\n"]}],"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","# For every sentence...\n","for sent in new_train['input_sentence']:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n","                        # This function also supports truncation and conversion\n","                        # to pytorch tensors, but we need to do padding, so we\n","                        # can't use these features :( .\n","                        #max_length = 128,          # Truncate all sentences.\n","                        #return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","\n","    # Add the encoded sentence to the list.\n","    input_ids.append(encoded_sent)\n","  # Print sentence 0, now as a list of IDs.\n","print('Original: ', new_train['input_sentence'].iloc[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10750,"status":"ok","timestamp":1687440318931,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"suhk2en_v3gl","outputId":"9d1a4ee4-8f0b-4e5c-dfab-11b0f648896b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original:  [CLS] ويؤثرون على أنفسهم ولو كان بهم خصاصة [SEP] : آثره على نفسه: قدمه واختصه بالخير :- { } .\n","Token IDs: [2, 549, 1275, 527, 319, 1725, 6449, 3, 31, 4164, 8110, 6819, 195, 29413, 195, 96, 98, 20]\n"]}],"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_test = []\n","# For every sentence...\n","for sent in test['input_sentence']:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n","                        # This function also supports truncation and conversion\n","                        # to pytorch tensors, but we need to do padding, so we\n","                        # can't use these features :( .\n","                        #max_length = 128,          # Truncate all sentences.\n","                        #return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","\n","    # Add the encoded sentence to the list.\n","    input_ids_test.append(encoded_sent)\n","  # Print sentence 0, now as a list of IDs.\n","print('Original: ', test['input_sentence'].iloc[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1687440318932,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"bzBpdzEqXK9y","outputId":"e10b8cf2-55f8-4e84-c20d-5c7a6e708358"},"outputs":[{"name":"stdout","output_type":"stream","text":["Max sentence length:  335\n"]}],"source":["print('Max sentence length: ', max([len(sen) for sen in input_ids]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7a9C1H6HXd6G"},"outputs":[],"source":["MAX_LEN = 492"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9696,"status":"ok","timestamp":1687440330025,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"tq1PzXFCPUDQ","outputId":"ed67a19d-0cb1-4caa-e884-38e2a35a21fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n","Installing collected packages: keras_preprocessing\n","Successfully installed keras_preprocessing-1.1.2\n"]}],"source":["pip install keras_preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1687440330025,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"6jw7xb--XaGD","outputId":"643e7bf0-f3cf-4e90-81d0-5982a5baa6f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Padding/truncating all sentences to 400 values...\n","\n","Padding token: \"[PAD]\", ID: 0\n","\\Done.\n"]}],"source":["# We'll borrow the `pad_sequences` utility function to do this.\n","#from keras.preprocessing.sequence import pad_sequences\n","from keras_preprocessing.sequence import pad_sequences\n","# Set the maximum sequence length.\n","# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n","# maximum training sentence length of 47...\n","MAX_LEN = 400\n","print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","# Pad our input tokens with value 0.\n","# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n","# as opposed to the beginning.\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n","                          value=0, truncating=\"post\", padding=\"post\")\n","print('\\Done.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1687440336396,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"ol7oZ2iXxMwQ","outputId":"89a006e1-60fb-4ddd-fe94-7682d5823344"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Padding/truncating all sentences to 400 values...\n","\n","Padding token: \"[PAD]\", ID: 0\n","\\Done.\n"]}],"source":["# We'll borrow the `pad_sequences` utility function to do this.\n","# from keras.preprocessing.sequence import pad_sequences\n","# Set the maximum sequence length.\n","# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n","# maximum training sentence length of 47...\n","# MAX_LEN = 400\n","print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","# Pad our input tokens with value 0.\n","# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n","# as opposed to the beginning.\n","input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\",\n","                          value=0, truncating=\"post\", padding=\"post\")\n","print('\\Done.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrTrM8rJWh5A"},"outputs":[],"source":["# Create attention masks\n","attention_masks = []\n","# For each sentence...\n","for sent in input_ids:\n","\n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","\n","    # Store the attention mask for this sentence.\n","    attention_masks.append(att_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZ-SSJmRxh-x"},"outputs":[],"source":["# Create attention masks\n","attention_masks_test = []\n","# For each sentence...\n","for sent in input_ids_test:\n","\n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","\n","    # Store the attention mask for this sentence.\n","    attention_masks_test.append(att_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqCK5tdJXx9I"},"outputs":[],"source":["train_labels = new_train['label'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBL94rU_x4qT"},"outputs":[],"source":["test_labels = test['label'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88C4MuLfZlip"},"outputs":[],"source":["# # Use train_test_split to split our data into train and validation sets for\n","# # training\n","# from sklearn.model_selection import train_test_split\n","# # Use 90% for training and 10% for validation.\n","# train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, df_labels,\n","#                                                             random_state=2018, test_size=0.2)\n","# # Do the same for the masks.\n","# train_masks, validation_masks, _, _ = train_test_split(attention_masks, df_labels,\n","#                                              random_state=2018, test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVFoWhuLXmEI"},"outputs":[],"source":["# Convert all inputs and labels into torch tensors, the required datatype\n","# for our model.\n","train_inputs = torch.tensor(input_ids)\n","validation_inputs = torch.tensor(input_ids_test)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(test_labels)\n","train_masks = torch.tensor(attention_masks)\n","validation_masks = torch.tensor(attention_masks_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4IM1asnmYLMZ"},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","# The DataLoader needs to know our batch size for training, so we specify it\n","# here.\n","# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n","# 16 or 32.\n","batch_size = 8\n","# Create the DataLoader for our training set.\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687440440659,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"NediaOn4Yf5g","outputId":"ce85e674-e24f-4537-e448-f31eabf4f761"},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU available, using the CPU instead.\n"]}],"source":["import torch\n","# If there's a GPU available...\n","if torch.cuda.is_available():\n","    # Tell PyTorch to use the GPU.\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["61559d49919e4d49ae343bd93a3656a6","7acc74f8e4014d93aba3e28ab118a18d","813e408ed050442ea0e462bd79031174","b74afa6d0d404c989f5862c471675ac5","14af66e0b9954f21b09bd1f44008ca13","f4ab212e00cf44de815e3bfe026f989b","f8373950e17e42ce88c63994ca987e42","bcc15fe76a0c48d18829e3061a0e62c1","2f67a90e035e42bf8558b504c67ad3d0","026c965f58e34d00a66dc71080dcc07b","538b92cabd6a4e7287db3b39b56f8a3b"]},"executionInfo":{"elapsed":13623,"status":"ok","timestamp":1687440460950,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"7iQU62eNYTWI","outputId":"4becf43d-feb0-4da7-fc30-0fae63eb9c78"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61559d49919e4d49ae343bd93a3656a6","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","# Load BertForSequenceClassification, the pretrained BERT model with a single\n","# linear classification layer on top.\n","model = BertForSequenceClassification.from_pretrained(\n","  model_path, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","# Tell pytorch to run this model on the GPU.\n","# model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5hBIy8NRqwB8"},"outputs":[],"source":["model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1687440496382,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"b-nuKWjwdRTI","outputId":"8779fee6-7f74-4e6c-b5c7-9dab2ee0bf61"},"outputs":[{"name":"stdout","output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (64000, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"]}],"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","print('==== Embedding Layer ====\\n')\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== First Transformer ====\\n')\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== Output Layer ====\\n')\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-nAAdJF8dgjC"},"outputs":[],"source":["params = list(model.named_parameters())\n","for name, param in params[-5:]:\n","    # print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","    param.requires_grad = True\n","for name, param in params[:-6]:\n","    # print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","    param.requires_grad = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1687440509614,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"DhB44_TuYjWB","outputId":"25deb7eb-0ffb-4836-e8cb-9e5575eb5b9f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["\n","# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","from transformers import get_linear_schedule_with_warmup\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 1\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mKJ2hy06Ys6j"},"outputs":[],"source":["import numpy as np\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zoF_VONuY2zM"},"outputs":[],"source":["import time\n","import datetime\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6mK9ZqdRY6Jr","outputId":"be3e9ec6-d46c-4cef-d0aa-926e2edeb30b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n","  Batch    40  of  3,108.    Elapsed: 0:25:07.\n","  Batch    80  of  3,108.    Elapsed: 0:49:18.\n","  Batch   120  of  3,108.    Elapsed: 1:14:02.\n","  Batch   160  of  3,108.    Elapsed: 1:38:15.\n","  Batch   200  of  3,108.    Elapsed: 2:02:50.\n","  Batch   240  of  3,108.    Elapsed: 2:26:43.\n","  Batch   280  of  3,108.    Elapsed: 2:50:29.\n"]}],"source":["import random\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    # Perform one full pass over the training set.\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","    # Put the model into training mode. Don't be mislead--the call to\n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","        # Unpack this training batch from our dataloader.\n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids\n","        #   [1]: attention masks\n","        #   [2]: labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because\n","        # accumulating the gradients is \"convenient while training RNNs\".\n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here:\n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        outputs = model(b_input_ids,\n","                    token_type_ids=None,\n","                    attention_mask=b_input_mask,\n","                    labels=b_labels)\n","\n","        # The call to `model` always returns a tuple, so we need to pull the\n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value\n","        # from the tensor.\n","        total_loss += loss.item()\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","        # Update the learning rate.\n","        scheduler.step()\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)\n","\n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","    print(\"\")\n","    print(\"Running Validation...\")\n","    t0 = time.time()\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","    # Tracking variables\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which\n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here:\n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask)\n","\n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","\n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","print(\"\")\n","print(\"Training complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlRUADdkjnb0"},"outputs":[],"source":["# Set the batch size.\n","batch_size = 32\n","# Create the DataLoader.\n","prediction_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139340,"status":"ok","timestamp":1687431841677,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"EhLUqIaojx0o","outputId":"2d2dd93c-2201-418a-b450-d5d138b6bef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicting labels for 6,172 test sentences...\n","DONE.\n"]}],"source":["prediction_inputs = validation_inputs\n","# =validation_masks\n","# =validation_labels\n","# Prediction on test set\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","# Put model in evaluation mode\n","model.eval()\n","# Tracking variables\n","predictions , true_labels = [], []\n","# Predict\n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","\n","  # Telling the model not to compute or store gradients, saving memory and\n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None,\n","                      attention_mask=b_input_mask)\n","  logits = outputs[0]\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","print('DONE.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1494,"status":"ok","timestamp":1687431939754,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"oDzwlP43kTlh","outputId":"f617b59a-5a98-433e-f3a4-a41d75c96128"},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive samples: 15549 of 31098 (50.00%)\n"]}],"source":["print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1440,"status":"ok","timestamp":1687431943566,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"kURQFsdqk92f","outputId":"58759ddf-eaab-4960-e811-e90c5a701fdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Calculating Matthews Corr. Coef. for each batch...\n"]}],"source":["from sklearn.metrics import matthews_corrcoef\n","matthews_set = []\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","# For each input batch...\n","for i in range(len(true_labels)):\n","\n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","\n","  # Calculate and store the coef for this batch.\n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n","  matthews_set.append(matthews)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687431946722,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"_uaTe1e1lijw","outputId":"7d6d29ef-bd7e-4df5-80e1-9240719a253b"},"outputs":[{"name":"stdout","output_type":"stream","text":["MCC: 0.591\n"]}],"source":["# Combine the predictions for each batch into a single list of 0s and 1s.\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = [item for sublist in true_labels for item in sublist]\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","print('MCC: %.3f' % mcc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bY1stbsnJASz"},"outputs":[],"source":["# y_true.sum()/len(y_true)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1035,"status":"ok","timestamp":1687431950641,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"qKLRVy8Xl47S","outputId":"ffe5dd38-a16f-49df-c689-e48974e1580d"},"outputs":[{"data":{"text/plain":["(0.7875891121192482, 0.7875891121192482, 0.7875891121192482, None)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support\n","y_true = flat_predictions\n","y_pred = flat_true_labels\n","# precision_recall_fscore_support(y_true, y_pred, average='macro')\n","precision_recall_fscore_support(y_true, y_pred, average='micro')\n","# precision_recall_fscore_support(y_true, y_pred, average='weighted')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687431952989,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"8-JKgtWEmSUj","outputId":"f1871c79-b949-4920-a05b-2cbc8e650b0e"},"outputs":[{"data":{"text/plain":["(array([0.66829427, 0.90580645]),\n"," array([0.87547974, 0.733734  ]),\n"," array([0.75798412, 0.81074058]),\n"," array([2345, 3827]))"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["precision_recall_fscore_support(y_true, y_pred, average=None,\n","labels=[0, 1])"]},{"cell_type":"markdown","metadata":{"id":"C2l5__5oWeIN"},"source":["# END of pyorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wqmbnGFIhfyw"},"outputs":[],"source":["  # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","with torch.no_grad():\n","    # Forward pass, calculate logit predictions.\n","    # This will return the logits rather than the loss because we have\n","    # not provided labels.\n","    # token_type_ids is the same as the \"segment ids\", which\n","    # differentiates sentence 1 and 2 in 2-sentence tasks.\n","    # The documentation for this `model` function is here:\n","    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","    outputs = model(b_input_ids,\n","                    token_type_ids=None,\n","                    attention_mask=b_input_mask)\n","\n","# Get the \"logits\" output by the model. The \"logits\" are the output\n","# values prior to applying an activation function like the softmax.\n","logits = outputs[0]\n","# Move logits and labels to CPU\n","logits = logits.detach().cpu().numpy()\n","label_ids = b_labels.to('cpu').numpy()\n","\n","# Calculate the accuracy for this batch of test sentences.\n","tmp_eval_accuracy = flat_accuracy(logits, label_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYEFqbiuZeIM"},"outputs":[],"source":["new_df_pairs.sample(frac=1)\n","msk = np.random.rand(len(new_df_pairs)) < 0.8\n","train = new_df_pairs[msk]\n","test = new_df_pairs[~msk]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SYAO6NSZw02"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","import pandas as pd\n","import sys\n","\n","import re\n","import numpy as np\n","from tensorflow.keras import regularizers\n","import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQ2S436OVtra"},"outputs":[],"source":["def encode_sentence(s, tokenizer):\n","   tokens = list(tokenizer.tokenize(s))\n","   tokens.append('[SEP]')\n","   return tokenizer.convert_tokens_to_ids(tokens)\n","\n","def bert_encode(glue_dict, tokenizer):\n","  num_examples = len(glue_dict[\"sentence1\"])\n","\n","  sentence1 = tf.ragged.constant([\n","      encode_sentence(s, tokenizer)\n","      for s in glue_dict[\"sentence1\"]])\n","  sentence2 = tf.ragged.constant([\n","      encode_sentence(s, tokenizer)\n","       for s in glue_dict[\"sentence2\"]])\n","\n","  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n","  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n","\n","  input_mask = tf.ones_like(input_word_ids).to_tensor()\n","\n","  type_cls = tf.zeros_like(cls)\n","  type_s1 = tf.zeros_like(sentence1)\n","  type_s2 = tf.ones_like(sentence2)\n","  input_type_ids = tf.concat(\n","      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n","\n","  inputs = {\n","      'input_word_ids': input_word_ids.to_tensor(),\n","      'input_mask': input_mask,\n","      'input_type_ids': input_type_ids}\n","\n","  return inputs\n","dict_train = {'sentence1':train[\"def\"],\"sentence2\":train[\"ex\"]}\n","train_data_set = bert_encode(dict_train, tokenizer)\n","train_labels = train['label']\n","train_labels = tf.convert_to_tensor(train_labels.tolist())\n","\n","# glue_test = bert_encode(glue['test'], tokenizer)\n","# glue_test_labels  = glue['test']['label']"]},{"cell_type":"markdown","metadata":{"id":"j6QR2Ji-UcaS"},"source":["# Tensor flow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4477,"status":"ok","timestamp":1687257873729,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"uMJejXaw92oU","outputId":"ba40cffa-c187-4352-fc5e-88d96c132de0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1272,"status":"ok","timestamp":1687257874980,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"9LTm12eF-5rx","outputId":"34a97903-ced5-4670-e7c7-609b37e6e9a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'arabert'...\n","remote: Enumerating objects: 600, done.\u001b[K\n","remote: Counting objects: 100% (65/65), done.\u001b[K\n","remote: Compressing objects: 100% (33/33), done.\u001b[K\n","remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n","Receiving objects: 100% (600/600), 9.14 MiB | 18.39 MiB/s, done.\n","Resolving deltas: 100% (339/339), done.\n"]}],"source":["!git clone https://github.com/aub-mind/arabert.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zUL1_TGAOOv"},"outputs":[],"source":["import sys\n","# the mock-0.3.1 dir contains testcase.py, testutils.py & mock.py\n","sys.path.append('/content/arabert')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8096,"status":"ok","timestamp":1687257883068,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"4fg_HNV7AXZ2","outputId":"bae27f21-7e4a-4732-f2fd-460416789d4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyarabic\n","  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n","Installing collected packages: pyarabic\n","Successfully installed pyarabic-0.6.15\n"]}],"source":["!pip install pyarabic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4530,"status":"ok","timestamp":1687257887591,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"pN6EoRfpAXfJ","outputId":"a5f3b354-8b6f-4fb3-eed8-f9db8684d814"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting farasapy\n","  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.65.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.4)\n","Installing collected packages: farasapy\n","Successfully installed farasapy-0.0.14\n"]}],"source":["!pip install farasapy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9969,"status":"ok","timestamp":1687258315183,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"NzyI7fXiaMTI","outputId":"b8f770cc-f603-4407-8763-83a56fc0b1da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: arabert in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: PyArabic in /usr/local/lib/python3.10/dist-packages (from arabert) (0.6.15)\n","Requirement already satisfied: farasapy in /usr/local/lib/python3.10/dist-packages (from arabert) (0.0.14)\n","Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.10/dist-packages (from arabert) (1.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy->arabert) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy->arabert) (4.65.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from PyArabic->arabert) (1.16.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (3.4)\n"]}],"source":["pip install arabert"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8559,"status":"ok","timestamp":1687260415189,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"A4R-nWoGjm4R","outputId":"ee4f51d0-14c7-41d7-abf5-04c968ac01bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"]}],"source":["pip install tensorflow --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pP_jxU3cjKRm"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5811,"status":"ok","timestamp":1687260460773,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"CS0SS-Pe95_D","outputId":"984292e5-5f16-4621-bc8e-e6f10b4dee2a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at aubmindlab/bert-base-arabert were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import AutoTokenizer, AutoModel, BertModel\n","#from arabert.preprocess import never_split_tokens\n","from farasa.segmenter import FarasaSegmenter\n","\n","arabert_tokenizer = AutoTokenizer.from_pretrained(\n","    \"aubmindlab/bert-base-arabert\",\n","    do_lower_case=False,\n","    do_basic_tokenize=True)\n","arabert_model = AutoModel.from_pretrained(\"aubmindlab/bert-base-arabert\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"elapsed":8,"status":"error","timestamp":1687261101194,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"F_z2xCWo-Dli","outputId":"4013715b-34cc-4967-bcea-38a187d1b1e1"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-863e8928ab68>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0marabert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0marabert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m115\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'BertModel' object has no attribute 'compile'"]}],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","arabert_model.base_model.compile(optimizer=optimizer, loss=loss)\n","arabert_model.fit( train_data, train_labels, epochs=2, steps_per_epoch=115)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWR5Czw0Ii-I"},"outputs":[],"source":["!pip install tf-models-official"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549},"executionInfo":{"elapsed":24,"status":"error","timestamp":1687258869760,"user":{"displayName":"Tymaa Hammouda","userId":"14535363312555966442"},"user_tz":-180},"id":"MgX4KLoeIcGF","outputId":"702d4b5c-3274-47ff-ff04-49fd04bf2f0a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]},{"ename":"ImportError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-83-fa780cc93d39>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load the required submodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'bert' from 'official.nlp' (/usr/local/lib/python3.10/dist-packages/official/nlp/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","\n","# import tensorflow_hub as hub\n","# import tensorflow_datasets as tfds\n","# tfds.disable_progress_bar()\n","\n","from official.modeling import tf_utils\n","from official import nlp\n","from official.nlp import bert\n","\n","# Load the required submodules\n","import official.nlp.optimization\n","import official.nlp.bert.bert_models\n","import official.nlp.bert.configs\n","import official.nlp.bert.run_classifier\n","import official.nlp.bert.tokenization\n","import official.nlp.data.classifier_data_lib\n","import official.nlp.modeling.losses\n","import official.nlp.modeling.models\n","import official.nlp.modeling.networks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXUZmNhlG8cR"},"outputs":[],"source":["df = pd.read_parquet(\"/content/drive/MyDrive/masters/new_df_pairs\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1UMZ5P-I6kb"},"outputs":[],"source":["new_df_pairs = df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GypZTSQuHuOQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkXiwr3iI8KN"},"outputs":[],"source":["gs_folder_bert = '/content/drive/MyDrive/tf_arabert01'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GigJkv7ZJXwx"},"outputs":[],"source":["tokenizer = bert.tokenization.FullTokenizer(\n","    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n","     do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Up6FNuuA94k4"},"outputs":[],"source":["def encode_sentence(s, tokenizer):\n","   tokens = list(tokenizer.tokenize(s))\n","   tokens.append('[SEP]')\n","   return tokenizer.convert_tokens_to_ids(tokens)\n","\n","def bert_encode(glue_dict, tokenizer):\n","  num_examples = len(glue_dict[\"sentence1\"])\n","\n","  sentence1 = tf.ragged.constant([\n","      encode_sentence(s, tokenizer)\n","      for s in glue_dict[\"sentence1\"]])\n","  sentence2 = tf.ragged.constant([\n","      encode_sentence(s, tokenizer)\n","       for s in glue_dict[\"sentence2\"]])\n","\n","  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n","  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n","\n","  input_mask = tf.ones_like(input_word_ids).to_tensor()\n","\n","  type_cls = tf.zeros_like(cls)\n","  type_s1 = tf.zeros_like(sentence1)\n","  type_s2 = tf.ones_like(sentence2)\n","  input_type_ids = tf.concat(\n","      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n","\n","  inputs = {\n","      'input_word_ids': input_word_ids.to_tensor(),\n","      'input_mask': input_mask,\n","      'input_type_ids': input_type_ids}\n","\n","  return inputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRZ8fFd2-Gft"},"outputs":[],"source":["dict_train = {'sentence1':train[\"def\"],\"sentence2\":train[\"ex\"]}\n","train_data_set = bert_encode(dict_train, tokenizer)\n","train_labels = train['label']\n","train_labels = tf.convert_to_tensor(train_labels.tolist())\n","\n","# glue_test = bert_encode(glue['test'], tokenizer)\n","# glue_test_labels  = glue['test']['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIvXXusP_3xi"},"outputs":[],"source":["dict_test = {'sentence1':test[\"def\"],\"sentence2\":test[\"ex\"]}\n","test_data_set = bert_encode(dict_test, tokenizer)\n","test_labels = test['label']\n","test_labels = tf.convert_to_tensor(test_labels.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otHMGsHzLe5N"},"outputs":[],"source":["# def encode_sentence(s):\n","#    tokens = list(tokenizer.tokenize(s))\n","#    tokens.append('[SEP]')\n","#    return tokenizer.convert_tokens_to_ids(tokens)\n","\n","# sentence1 = tf.ragged.constant([\n","#     encode_sentence(s) for s in train[\"def\"]])\n","# sentence2 = tf.ragged.constant([\n","#     encode_sentence(s) for s in train[\"ex\"]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOiCCB3fLgck"},"outputs":[],"source":["# cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n","# input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCVJpcTXLi4l"},"outputs":[],"source":["# input_mask = tf.ones_like(input_word_ids).to_tensor()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TklY4SfrLlE2"},"outputs":[],"source":["# type_cls = tf.zeros_like(cls)\n","# type_s1 = tf.zeros_like(sentence1)\n","# type_s2 = tf.ones_like(sentence2)\n","# input_type_ids = tf.concat([type_cls, type_s1, type_s2], axis=-1).to_tensor()\n","\n","# # plt.pcolormesh(input_type_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abxy8e7gLnnq"},"outputs":[],"source":["import  json\n","bert_config_file = os.path.join(gs_folder_bert, \"config.json\")\n","config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n","bert_config = bert.configs.BertConfig.from_dict(config_dict)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anMteV2pLp1Y"},"outputs":[],"source":["bert_classifier, bert_encoder = bert.bert_models.classifier_model(\n","    bert_config, num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ys_7WBheVj7k"},"outputs":[],"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6l0jzYAA5ioZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aj68IldQLsBh"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQ6gKnFnLwyi"},"outputs":[],"source":["# train_labels = train['label']\n","# train_labels = tf.convert_to_tensor(train_labels.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYhobuB8L0GE"},"outputs":[],"source":["# train_data= {'input_word_ids':input_word_ids.to_tensor(),\n","#              'input_mask':    input_mask,\"input_type_ids\":  input_type_ids}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMwFTQVtZ41a"},"outputs":[],"source":["# import tensorflow_hub as hub\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgA7unvXohjV"},"outputs":[],"source":["!cp  /content/drive/MyDrive/tf_arabert01/arabert01_model.ckpt.index /content/drive/MyDrive/Checkpoints/arabert01_model.ckpt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvUciotHexvo"},"outputs":[],"source":["# # tf.compat.v1.train.import_meta_graph('/content/drive/MyDrive/tf_arabert01/arabert01_model.meta')\n","\n","# with tf.compat.v1.Session() as sess:\n","#   new_saver = tf.compat.v1.train.import_meta_graph('/content/drive/MyDrive/tf_arabert01/arabert01_model.meta')\n","#   new_saver.restore(sess, tf.train.latest_checkpoint('/content/drive/MyDrive/tf_arabert01/'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-a3yX3Vle9B"},"outputs":[],"source":["checkpoint =  tf.compat.v1.train.load_checkpoint('/content/drive/MyDrive/tf_arabert01/arabert01_model.ckpt.index')\n","# checkpoint.restore(\"/content/drive/MyDrive/tf_arabert01/arabert01_model.ckpt.index\").expect_partial()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42-KBYrTT-Gg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0D2nexeUKGo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sT_XZU2HcPfd"},"outputs":[],"source":["# tf.train.Checkpoint.read(save_path=\"/content/drive/MyDrive/tf_arabert01/\").assert_consumed()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OYshallnCWgm"},"outputs":[],"source":["tf.reduce_sum(train_labels).numpy()/len(train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvVVCMVrL3be"},"outputs":[],"source":["# Set up epochs and steps\n","epochs = 20\n","batch_size = 16\n","eval_batch_size = 15\n","\n","train_data_size = len(train_labels)\n","steps_per_epoch = int(train_data_size / batch_size)\n","num_train_steps = steps_per_epoch * epochs\n","warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n","\n","# creates an optimizer with learning rate schedule\n","optimizer = nlp.optimization.create_optimizer(\n","    2e-5*10, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lN9errWwL5Dk"},"outputs":[],"source":["metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","bert_classifier.compile(\n","    optimizer=optimizer,\n","    loss=loss,\n","    metrics=metrics)\n","\n","bert_classifier.fit(\n","      train_data_set, train_labels,\n","      validation_data=(test_data_set, test_labels),\n","      batch_size=16,\n","      epochs=epochs)"]},{"cell_type":"markdown","metadata":{"id":"GCzSwc5wCaTo"},"source":["bert_classifier.fit(\n","      train_data_set, train_labels,\n","      validation_data=(test_data_set, test_labels),\n","      batch_size=8,\n","      epochs=epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9NP9630Cb7L"},"outputs":[],"source":["# bert_classifier.load_weights('/content/drive/MyDrive/tf_arabert01/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZghMpItSDpAh"},"outputs":[],"source":["# with tf.compat.v1.Session() as sess:\n","#     saver = tf.compat.v1.train.import_meta_graph('/content/drive/MyDrive/tf_arabert01/arabert01_model.meta')\n","#     saver.restore(sess, \"/content/drive/MyDrive/tf_arabert01/arabert01_model.ckpt.index\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjVoh4LHL6p8"},"outputs":[],"source":["class BertLayer(tf.compat.v1.layers.Layer):\n","    def __init__(self, n_fine_tune_layers=10, **kwargs):\n","        self.n_fine_tune_layers = n_fine_tune_layers\n","        self.trainable = True\n","        self.output_size = 768\n","        super(BertLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.bert = hub.Module(\n","            bert_path,\n","            trainable=self.trainable,\n","            name=\"{}_module\".format(self.name)\n","        )\n","        trainable_vars = self.bert.variables\n","\n","        # Remove unused layers\n","        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n","\n","        # Select how many layers to fine tune\n","        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n","\n","        # Add to trainable weights\n","        for var in trainable_vars:\n","            self._trainable_weights.append(var)\n","\n","        # Add non-trainable weights\n","        for var in self.bert.variables:\n","            if var not in self._trainable_weights:\n","                self._non_trainable_weights.append(var)\n","\n","        super(BertLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n","        input_ids, input_mask, segment_ids = inputs\n","        bert_inputs = dict(\n","            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n","        )\n","        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","            \"pooled_output\"\n","        ]\n","        return result\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxHVzvagYz-c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kP1CWx3BWiHe"},"outputs":[],"source":["max_seq_length= 450\n","in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n","in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n","in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n","bert_inputs = [in_id, in_mask, in_segment]\n","\n","# Instantiate the custom Bert Layer defined above\n","bert_output = BertLayer(n_fine_tune_layers=4)(bert_inputs)\n","\n","# Build the rest of the classifier\n","dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n","pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n","\n","model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(\n","    [train_input_ids, train_input_masks, train_segment_ids],\n","    train_labels,\n","    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n","    epochs=1,\n","    batch_size=32\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fxc4d-6_Ywid"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["C2l5__5oWeIN","j6QR2Ji-UcaS"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"026c965f58e34d00a66dc71080dcc07b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02d2b6e37158448e89099e42b690a38e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02f6fbe8fec2442a8c53594cd47e86be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07aaeed6f610403f85be74888826acbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a3a32b795984105848d7964ef8f9975","IPY_MODEL_c8a96f2a17594bd9bbeb9e04f6273d69","IPY_MODEL_4cb688907f7442a7b5511e5d1a4f02eb"],"layout":"IPY_MODEL_8a3dccf5cd5147339febb57fda7ec673"}},"14af66e0b9954f21b09bd1f44008ca13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"150f139641bf47bda20e3c59cab5f072":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c98ff8aefb649cda399f4de5a01dccf","placeholder":"​","style":"IPY_MODEL_caabed851a2440caae4f241c58e2a6f7","value":" 112/112 [00:00&lt;00:00, 2.24kB/s]"}},"2453bd7e013344509b4474375780f79d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f67a90e035e42bf8558b504c67ad3d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30de6934fb0349c2b74c121897e79aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38947973d4bb4a73bd5a8bfbacb85885":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42267800a25540c980dbc9eeacafaeca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6be1c959aa294505a8a34f67a333ad3d","IPY_MODEL_e6972d3b6d56436f815337fdcd999cf8","IPY_MODEL_6d01ac8faecd40b2966b0291fb4edf65"],"layout":"IPY_MODEL_9ae6c63df7124e9c91a4f5e7a21007fe"}},"45425c9b772f441697ccac4edf8ec7e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"485d34a73e944e65acbb2e22ce12c286":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ac73de6825b49baa03329429f9c1486":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cb688907f7442a7b5511e5d1a4f02eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_adeb407035dc43488b59f94331be48be","placeholder":"​","style":"IPY_MODEL_febe57df0d0b4023b5b257483ee2c3a0","value":" 381/381 [00:00&lt;00:00, 18.7kB/s]"}},"50d85f84abee4d5cadaf0a4c12703ae2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"538b92cabd6a4e7287db3b39b56f8a3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5791c87669594f61bdf628b89f57e20c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5883123b5a8b42589af29d1a190adac4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a3a32b795984105848d7964ef8f9975":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5883123b5a8b42589af29d1a190adac4","placeholder":"​","style":"IPY_MODEL_dd966526b04b463aa516c85291560e6f","value":"Downloading (…)okenizer_config.json: 100%"}},"5c98ff8aefb649cda399f4de5a01dccf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61559d49919e4d49ae343bd93a3656a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7acc74f8e4014d93aba3e28ab118a18d","IPY_MODEL_813e408ed050442ea0e462bd79031174","IPY_MODEL_b74afa6d0d404c989f5862c471675ac5"],"layout":"IPY_MODEL_14af66e0b9954f21b09bd1f44008ca13"}},"639217c3add64bfdbf66ba3bacacae0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cdff14b059f43b99a9ddd32a3fb3070","IPY_MODEL_dd8b3f39bfbe44a69b818a667cac3215","IPY_MODEL_84d82a2d64c14382b03d31ec6f017e03"],"layout":"IPY_MODEL_abdb738b1bec4df78d99147765a728bc"}},"6be1c959aa294505a8a34f67a333ad3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50d85f84abee4d5cadaf0a4c12703ae2","placeholder":"​","style":"IPY_MODEL_02d2b6e37158448e89099e42b690a38e","value":"Downloading (…)solve/main/vocab.txt: "}},"6cdff14b059f43b99a9ddd32a3fb3070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eea13ec7baa742568baf0b1114b5fa62","placeholder":"​","style":"IPY_MODEL_9cbef5f6b7dc4335a078ebd8e89e00dc","value":"Downloading (…)lve/main/config.json: 100%"}},"6d01ac8faecd40b2966b0291fb4edf65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad58c1c205dd4dc0969a66822860c25f","placeholder":"​","style":"IPY_MODEL_30de6934fb0349c2b74c121897e79aca","value":" 825k/? [00:00&lt;00:00, 4.13MB/s]"}},"7acc74f8e4014d93aba3e28ab118a18d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ab212e00cf44de815e3bfe026f989b","placeholder":"​","style":"IPY_MODEL_f8373950e17e42ce88c63994ca987e42","value":"Downloading model.safetensors: 100%"}},"7e21a719db0440f38474d1e10900c9b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1b0598b83a84801964126ef41c99f71","placeholder":"​","style":"IPY_MODEL_4ac73de6825b49baa03329429f9c1486","value":"Downloading (…)cial_tokens_map.json: 100%"}},"813e408ed050442ea0e462bd79031174":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcc15fe76a0c48d18829e3061a0e62c1","max":543432324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f67a90e035e42bf8558b504c67ad3d0","value":543432324}},"84d82a2d64c14382b03d31ec6f017e03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6f627dc990549f296a74bbfc5271b13","placeholder":"​","style":"IPY_MODEL_c56d57f1428a4f19bd37a4f69983a270","value":" 384/384 [00:00&lt;00:00, 14.4kB/s]"}},"8a3dccf5cd5147339febb57fda7ec673":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98390f53fc02423da5ba77885b09a247":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02f6fbe8fec2442a8c53594cd47e86be","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2af1ab7b81f4b7e829a1efd515abf6e","value":112}},"9ae6c63df7124e9c91a4f5e7a21007fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cbef5f6b7dc4335a078ebd8e89e00dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abdb738b1bec4df78d99147765a728bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad58c1c205dd4dc0969a66822860c25f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adeb407035dc43488b59f94331be48be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6f627dc990549f296a74bbfc5271b13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b74afa6d0d404c989f5862c471675ac5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_026c965f58e34d00a66dc71080dcc07b","placeholder":"​","style":"IPY_MODEL_538b92cabd6a4e7287db3b39b56f8a3b","value":" 543M/543M [00:06&lt;00:00, 69.9MB/s]"}},"bcc15fe76a0c48d18829e3061a0e62c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2af1ab7b81f4b7e829a1efd515abf6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c56d57f1428a4f19bd37a4f69983a270":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8a96f2a17594bd9bbeb9e04f6273d69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45425c9b772f441697ccac4edf8ec7e7","max":381,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eed9280b54254569b3c21fe2277a9cc1","value":381}},"caabed851a2440caae4f241c58e2a6f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d58382cfbc6249018351a2e353d43368":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e21a719db0440f38474d1e10900c9b9","IPY_MODEL_98390f53fc02423da5ba77885b09a247","IPY_MODEL_150f139641bf47bda20e3c59cab5f072"],"layout":"IPY_MODEL_485d34a73e944e65acbb2e22ce12c286"}},"dd8b3f39bfbe44a69b818a667cac3215":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5791c87669594f61bdf628b89f57e20c","max":384,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2453bd7e013344509b4474375780f79d","value":384}},"dd966526b04b463aa516c85291560e6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1b0598b83a84801964126ef41c99f71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6972d3b6d56436f815337fdcd999cf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f323160c757249479434e2724e501ab8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38947973d4bb4a73bd5a8bfbacb85885","value":1}},"eea13ec7baa742568baf0b1114b5fa62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed9280b54254569b3c21fe2277a9cc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f323160c757249479434e2724e501ab8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f4ab212e00cf44de815e3bfe026f989b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8373950e17e42ce88c63994ca987e42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"febe57df0d0b4023b5b257483ee2c3a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}